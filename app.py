import os
import gradio as gr
import pandas as pd
import numpy as np
import tempfile
import json
from sklearn.neighbors import NearestNeighbors
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

def auto_detect_data_path():
    candidates = [
        "ìµœì¢…_ë°ì´í„°.csv",
        "í•™ì› ë°ì´í„°_ì •ë¦¬_v6_ì»¬ëŸ¼ì •ë¦¬__í‘œì‹œëª…ì¶”ê°€.csv",
        "ì§„ì§œ ìµœì¢…ë³¸ ìë£Œ.xlsx",
        "academies_labeled.csv",
    ]
    for c in candidates:
        if os.path.exists(c):
            print("âœ… ìë™ìœ¼ë¡œ ë°ì´í„° íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤:", c)
            return c
    raise FileNotFoundError("âŒ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CSV ë˜ëŠ” XLSX íŒŒì¼ì„ ê°™ì€ í´ë”ì— ë‘ì„¸ìš”.")

def read_any(path: str) -> pd.DataFrame:
    ext = os.path.splitext(path)[-1].lower()
    if ext in [".xlsx", ".xls"]:
        return pd.read_excel(path, dtype=object)
    elif ext in [".csv", ".txt"]:
        for enc in ["utf-8-sig", "utf-8", "cp949", "euc-kr", "latin1"]:
            try:
                return pd.read_csv(path, dtype=object, encoding=enc, engine="python")
            except Exception:
                pass
        raise RuntimeError("CSV ì¸ì½”ë”©ì„ í™•ì¸í•˜ì„¸ìš”.")
    else:
        raise ValueError("ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. (csv, xlsx ê¶Œì¥)")

def detect_admin_col(df: pd.DataFrame):
    exact_priority = ["í–‰ì •êµ¬ì—­ëª…", "ì‹œêµ°êµ¬", "ì‹œ/êµ°/êµ¬", "ìë©´ë™", "í–‰ì •ë™", "ìì¹˜êµ¬"]
    for c in df.columns:
        if str(c) in exact_priority:
            return c
    keywords = ["í–‰ì •êµ¬ì—­", "ì‹œêµ°êµ¬", "ì‹œ/êµ°/êµ¬", "ìë©´ë™", "í–‰ì •ë™", "ìì¹˜êµ¬"]
    for c in df.columns:
        cl = str(c).lower()
        if any(k in cl for k in [k.lower() for k in keywords]):
            if "êµ¬ë¶„" in str(c):
                continue
            return c
    for c in df.columns:
        if any(k in str(c) for k in ["ì£¼ì†Œ", "address"]):
            return c
    for c in df.columns:
        if df[c].dtype == object:
            return c
    return df.columns[0]

def detect_name_col(df: pd.DataFrame):
    priority = ["í‘œì‹œëª…", "í•™ì›ëª…_ì¶”ê°€", "í•™ì›ëª…", "í•™ì›ì´ë¦„", "ê¸°ê´€ëª…", "academy", "name"]
    for p in priority:
        for c in df.columns:
            if str(c).lower() == p.lower():
                return c
    for c in df.columns:
        cl = str(c).lower()
        if any(k in cl for k in ["í‘œì‹œëª…", "í•™ì›ëª…", "í•™ì›ì´ë¦„", "ê¸°ê´€ëª…", "academy", "name"]):
            return c
    obj_cols = [c for c in df.columns if df[c].dtype == object]
    if obj_cols:
        uniq_counts = [(c, df[c].astype(str).nunique(dropna=True)) for c in obj_cols]
        uniq_counts.sort(key=lambda x: x[1], reverse=True)
        return uniq_counts[0][0]
    return df.columns[0]

def ensure_display_name(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    if "í‘œì‹œëª…" in df.columns:
        return df
    admin_col = detect_admin_col(df)
    name_col  = detect_name_col(df)
    base = df[admin_col].astype(str).fillna("")
    name = df[name_col].astype(str).fillna("")
    disp = (base.str.strip() + " " + name.str.strip()).str.strip()
    df["í‘œì‹œëª…"] = disp.replace({"^$": np.nan}, regex=True)
    return df

def split_feature_columns(df: pd.DataFrame, exclude_cols):
    numeric_cols, categorical_cols = [], []
    for c in df.columns:
        if c in exclude_cols:
            continue
        series = pd.to_numeric(df[c], errors="coerce")
        if series.notna().mean() >= 0.5:
            numeric_cols.append(c)
        else:
            categorical_cols.append(c)
    for c in categorical_cols[:]:
        if any(k in str(c).lower() for k in ["í‰ì ","rating","ì ìˆ˜","ë¦¬ë·°","ìˆ˜ê°•","í•™ìƒìˆ˜","ì •ì›","ë¹„ìš©","ê°€ê²©","fee"]):
            categorical_cols.remove(c)
            numeric_cols.append(c)
    return numeric_cols, categorical_cols

def build_preprocessor(numeric_cols, categorical_cols):
    numeric_transformer = Pipeline(steps=[
        ("imputer", SimpleImputer(strategy="median")),
        ("scaler", StandardScaler()),
    ])
    try:
        categorical_transformer = Pipeline(steps=[
            ("imputer", SimpleImputer(strategy="most_frequent")),
            ("onehot", OneHotEncoder(handle_unknown="ignore", sparse_output=True)),
        ])
    except TypeError:
        categorical_transformer = Pipeline(steps=[
            ("imputer", SimpleImputer(strategy="most_frequent")),
            ("onehot", OneHotEncoder(handle_unknown="ignore", sparse=True)),
        ])
    preprocess = ColumnTransformer(
        transformers=[
            ("num", numeric_transformer, numeric_cols),
            ("cat", categorical_transformer, categorical_cols),
        ],
        remainder="drop",
    )
    return preprocess

def fit_knn(X_trans, metric="euclidean", n_neighbors=10):
    return NearestNeighbors(n_neighbors=n_neighbors, metric=metric).fit(X_trans)

def apply_hard_filters(df: pd.DataFrame, query_dict: dict, exclude_cols):
    if not query_dict:
        return df
    df_f = df.copy()
    for k, v in query_dict.items():
        if k not in df_f.columns:
            continue
        s = df_f[k]
        num_mask = pd.to_numeric(s, errors="coerce").notna()
        if pd.to_numeric(pd.Series([v]), errors="coerce").notna().iloc[0] and num_mask.mean() >= 0.5:
            vs = pd.to_numeric(s, errors="coerce")
            vv = float(pd.to_numeric(pd.Series([v]), errors="coerce").iloc[0])
            df_f = df_f[np.isfinite(vs) & (np.abs(vs - vv) <= 1e-6)]
        else:
            def norm(x): return str(x).strip().lower()
            nv = norm(v)
            df_f = df_f[s.apply(lambda x: norm(x) == nv)]
        if len(df_f) == 0:
            break
    return df_f

def recommend(df, preprocess, knn, exclude_cols, query_dict, top_n=5):
    X = df.drop(columns=list(exclude_cols), errors="ignore")
    q = pd.DataFrame([{c: np.nan for c in X.columns}])
    for k, v in (query_dict or {}).items():
        if k in q.columns:
            q.at[0, k] = v
    Q = preprocess.transform(q)
    n_nbrs = min(top_n, len(df))
    distances, indices = knn.kneighbors(Q, n_neighbors=n_nbrs)
    idx = indices[0].tolist()
    dist = distances[0].tolist()
    result = df.iloc[idx].copy()
    result.insert(0, "similarity_distance", dist)
    return result.head(top_n)

DATA_PATH = auto_detect_data_path()
df_all = read_any(DATA_PATH)
df_all = ensure_display_name(df_all)

cols = [str(c) for c in df_all.columns]
name_col = detect_name_col(df_all)
admin_col = detect_admin_col(df_all)
exclude_keywords = ["í‘œì‹œëª…","í–‰ì •êµ¬ì—­ëª…", "ê³¼ëª©ëª…", "í•™ì›ëª…","í•™ì›ì´ë¦„","ê¸°ê´€ëª…","name","academy","ì „í™”","ì—°ë½ì²˜","ì£¼ì†Œ","ìœ„ì¹˜","ì¢Œí‘œ","url","í™ˆí˜ì´ì§€","ë©”ëª¨","ë¹„ê³ ","ì„¤ëª…"]
exclude_cols = set([c for c in cols if any(k in str(c).lower() for k in exclude_keywords)])
numeric_cols, categorical_cols = split_feature_columns(df_all, exclude_cols)
DF_STATE = df_all.copy()
PREPROCESS = None
KNN = None

def prepare_model(admin_filter, metric = "euclidean", topn_build=25):
    global DF_STATE, PREPROCESS, KNN, numeric_cols, categorical_cols
    df = df_all.copy()
    if admin_filter and admin_filter != "(ì „ì²´)" and admin_col in df.columns:
        df = df[df[admin_col].astype(str) == str(admin_filter)].copy()
    X = df.drop(columns=list(exclude_cols), errors="ignore")
    num_cols, cat_cols = split_feature_columns(df, exclude_cols)
    PREPROCESS = build_preprocessor(num_cols, cat_cols)
    PREPROCESS.fit(X)
    X_trans = PREPROCESS.transform(X)
    KNN = fit_knn(X_trans, metric=metric, n_neighbors=min(topn_build, len(df)))
    DF_STATE = df
    numeric_cols[:] = num_cols
    categorical_cols[:] = cat_cols
    info = {"í–‰ ìˆ˜": len(df), "í•™ì›ëª… ì»¬ëŸ¼": str(name_col), "í–‰ì •êµ¬ì—­ ì»¬ëŸ¼": str(admin_col), "ìˆ«ìí˜• íŠ¹ì„± ìˆ˜": len(num_cols), "ë²”ì£¼í˜• íŠ¹ì„± ìˆ˜": len(cat_cols), "ê±°ë¦¬(metric)": metric}
    return json.dumps(info, ensure_ascii=False, indent=2)

def run_recommend_form(*args):
    if PREPROCESS is None or KNN is None:
        return "ë¨¼ì € ìƒë‹¨ì—ì„œ ëª¨ë¸ì„ ì¤€ë¹„í•˜ì„¸ìš”.", None, None
    metric = args[-2]
    top_n = int(args[-1])
    X_all = DF_STATE.drop(columns=list(exclude_cols), errors="ignore")
    feat_cols = list(X_all.columns)
    values = list(args[:-2])
    query_dict = {}
    for c, v in zip(feat_cols, values):
        if v is None or (isinstance(v, str) and v.strip() in ["", "(ì„ íƒ ì•ˆí•¨)"]):
            continue
        query_dict[c] = v
    df_f = apply_hard_filters(DF_STATE, query_dict, exclude_cols)
    if len(df_f) == 0:
        return "ì„ íƒí•œ ì¡°ê±´ì„ ëª¨ë‘ ë§Œì¡±í•˜ëŠ” í•™ì›ì´ ì—†ìŠµë‹ˆë‹¤. ì¡°ê±´ì„ ì™„í™”í•´ë³´ì„¸ìš”.", None, None
    Xf = df_f.drop(columns=list(exclude_cols), errors="ignore")
    Qf = PREPROCESS.transform(Xf)
    knn_local = fit_knn(Qf, metric=metric, n_neighbors=min(max(10, top_n), len(df_f)))
    result = recommend(df_f, PREPROCESS, knn_local, exclude_cols, query_dict, top_n)
    tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".csv")
    result.to_csv(tmp.name, index=False, encoding="utf-8-sig")
    return "ì™„ë£Œ", result, tmp.name

def run_recommend_form(*args):
    if PREPROCESS is None or KNN is None:
        return "ë¨¼ì € ìƒë‹¨ì—ì„œ ëª¨ë¸ì„ ì¤€ë¹„í•˜ì„¸ìš”.", None
    metric = "euclidean"
    top_n = int(args[-1])
    X_all = DF_STATE.drop(columns=list(exclude_cols), errors="ignore")
    feat_cols = list(X_all.columns)
    values = list(args[:-1])
    query_dict = {}
    for c, v in zip(feat_cols, values):
        if v is None or (isinstance(v, str) and v.strip() in ["", "(ì„ íƒ ì•ˆí•¨)"]):
            continue
        query_dict[c] = v

    df_f = apply_hard_filters(DF_STATE, query_dict, exclude_cols)
    if len(df_f) == 0:
        return "ì„ íƒí•œ ì¡°ê±´ì„ ëª¨ë‘ ë§Œì¡±í•˜ëŠ” í•™ì›ì´ ì—†ìŠµë‹ˆë‹¤. ì¡°ê±´ì„ ì™„í™”í•´ë³´ì„¸ìš”.", None

    Xf = df_f.drop(columns=list(exclude_cols), errors="ignore")
    Qf = PREPROCESS.transform(Xf)
    knn_local = fit_knn(Qf, metric=metric, n_neighbors=min(max(10, top_n), len(df_f)))
    result = recommend(df_f, PREPROCESS, knn_local, exclude_cols, query_dict, top_n)
    return "ì™„ë£Œ", result

custom_theme = gr.themes.Base(primary_hue="pink", secondary_hue="pink").set(
    body_background_fill="#ffffff",
    background_fill_primary="#ffffff",
    background_fill_secondary="#ffe6f0",
    border_color_primary="#ffc0cb",
    button_primary_background_fill="#ffc0cb",
    button_primary_background_fill_hover="#ffb6c1",
    button_primary_text_color="#4a001f",
    block_title_text_color="#d63384"
)

with gr.Blocks(title="í•™ì› ì¶”ì²œê¸° (KNNÂ·í•˜ë“œí•„í„°)", theme=custom_theme) as demo:
    gr.HTML(
        '''
        <div style="display:flex; align-items:center; justify-content:center; gap:20px; margin-top:30px;">
            
            <!-- ğŸŸª ì™¼ìª½ í•´ì»¤í†¤ ë¡œê³  -->
            <img src="https://drive.google.com/thumbnail?id=1WlOO7svUbfCE0fVOfkQWht4en2Rqjs3P"
                 alt="í•´ì»¤í†¤ ë¡œê³ "
                 style="width:70px; height:70px; border-radius:15px; box-shadow:0px 3px 6px rgba(0,0,0,0.15);">

            <!-- ğŸ“ Instudygram ë¡œê³  (Postimg ì´ë¯¸ì§€) -->
            <div style="background:#fff; padding:12px 25px; border-radius:15px; box-shadow:0px 4px 8px rgba(0,0,0,0.08);">
                <img src="https://i.postimg.cc/Pxh4JXLW/image.png"
                     alt="Instudygram ë¡œê³ "
                     style="width:200px; height:auto; display:block;">
            </div>

        </div>

        <div style="text-align:center; margin-top:10px;">
            <p style="color:#888; font-size:18px; margin-top:5px;">
                AI ê¸°ë°˜ í•™ì› ì¶”ì²œ í”Œë«í¼
            </p>
        </div>
        '''
    )



    with gr.Row():
        if admin_col in df_all.columns:
            admin_choices = ["(ì „ì²´)"] + sorted([str(v) for v in df_all[admin_col].dropna().astype(str).unique()])
        else:
            admin_choices = ["(ì „ì²´)"]
        admin_filter = gr.Dropdown(
        choices=admin_choices,
        value="(ì „ì²´)",
        label="ì§€ì—­ í•„í„°",
        scale=1,
    )

    prepare_btn = gr.Button("ê²€ìƒ‰ğŸ”", variant="primary", scale=1)
    prep_info = gr.Code(label="ëª¨ë¸ ìš”ì•½", interactive=False, elem_id="prep-box")
    

    # metric ì œê±°ëœ ìƒíƒœë¡œ ë³€ê²½
    prepare_btn.click(prepare_model, inputs=[admin_filter], outputs=[prep_info])


    gr.Markdown("<br><br>", visible=False)

    with gr.Tab("í¼ ì…ë ¥"):
        X = df_all.drop(columns=list(exclude_cols), errors="ignore")
        feat_cols = list(X.columns)
        inputs = []
        with gr.Accordion("ì…ë ¥ í¼(ë¯¸ì„ íƒ ì‹œì—ëŠ” ì§€ì—­ ì¡°ê±´ë§Œ ì ìš©ë©ë‹ˆë‹¤. )", open=True):
            for c in feat_cols:
                ser = DF_STATE[c].dropna()
                if pd.to_numeric(ser, errors="coerce").notna().mean() >= 0.5:
                    comp = gr.Number(label=f"{c} (ìˆ«ì)")
                else:
                    choices = ["(ì„ íƒ ì•ˆí•¨)"] + sorted([str(x) for x in ser.astype(str).unique()][:200])
                    comp = gr.Dropdown(choices=choices, value="(ì„ íƒ ì•ˆí•¨)", label=f"{c}")
                inputs.append(comp)
        with gr.Row():
            top_n = gr.Slider(3, 20, value=5, step=1, label="ì¶”ì²œ ê°œìˆ˜ Top-N")
            run_btn = gr.Button("ğŸ” ì¶”ì²œ ì‹¤í–‰", variant="primary", elem_id = "run-btn")
        status1 = gr.Textbox(label="ìƒíƒœ", interactive=False)
        out_df1 = gr.Dataframe(label="ì¶”ì²œ ê²°ê³¼", interactive=False, wrap=True)
        run_btn.click(run_recommend_form, inputs=[*inputs, top_n], outputs=[status1, out_df1])

    

demo.css = """
/* ================================
   ğŸ“Œ ì „ì²´ ë ˆì´ì•„ì›ƒ ë° ê¸°ë³¸ ì„¤ì •
================================ */
#filter-row {
    display: flex;
    justify-content: center;
    align-items: flex-start;
    gap: 25px;
    margin-top: 5px;
    margin-bottom: 20px;
}

#filter-box, #metric-box {
    background-color: #ffffff; /* ë‚´ë¶€ í°ìƒ‰ */
    border: 2px solid #ffb6c1; /* ìœ¤ê³½ì„ ë§Œ ë¶„í™ìƒ‰ */
    border-radius: 25px;
    padding: 25px;
    width: 260px;
    height: 130px;
    text-align: center;
    box-shadow: 0px 4px 10px rgba(255, 182, 193, 0.25);
    transition: all 0.2s ease-in-out;
}

#filter-box:hover, #metric-box:hover {
    transform: scale(1.03);
    box-shadow: 0px 6px 14px rgba(255, 182, 193, 0.4);
}

/* ================================
   ğŸ€ ì „ì²´ ì»¨í…Œì´ë„ˆ ë‘¥ê·¼ ìŠ¤íƒ€ì¼
================================ */
.gradio-container, .block, .box, .accordion, .dataframe {
    border-radius: 25px !important;
    overflow: hidden;
}

/* ================================
   ğŸ’— ë²„íŠ¼ ìŠ¤íƒ€ì¼
================================ */
.gr-button-primary {
    background-color: #ffb6c1 !important;
    border: none !important;
    color: #4a001f !important;
    border-radius: 20px !important;
    font-weight: 600;
}
.gr-button-primary:hover {
    background-color: #ff99cc !important;
}

/* ================================
   âœ¨ ì…ë ¥ì°½ ë° í¼ ìŠ¤íƒ€ì¼
================================ */
.input-field, .gr-input, .gr-textbox, .gr-dropdown, .gr-number, .gr-slider {
    font-size: 18px !important;
    color: #4a001f !important;
    background-color: #ffffff !important; /* ë‚´ë¶€ í°ìƒ‰ */
    border: 1.5px solid #ffb6c1 !important;
    border-radius: 18px !important;
    padding: 10px !important;
    box-shadow: 0 3px 8px rgba(255, 182, 193, 0.2);
}

/* ================================
   ğŸ©° í¼ ì „ì²´ ì¹´ë“œ ìŠ¤íƒ€ì¼
================================ */
.accordion, .block, .box {
    background-color: #ffffff !important; /* ë°•ìŠ¤ ë‚´ë¶€ í°ìƒ‰ */
    border: 2px solid #ffb6c1 !important; /* ë¶„í™ ìœ¤ê³½ì„  */
    border-radius: 25px !important;
    padding: 25px !important;
    box-shadow: 0px 4px 10px rgba(255, 182, 193, 0.25);
}

/* ë‚´ë¶€ ì…ë ¥ ìš”ì†Œ ê²½ê³„ ì œê±° */
.accordion > .block, .accordion > div > .block {
    border: none !important;
    background: transparent !important;
    box-shadow: none !important;
    padding: 8px 0 !important;
}

/* í¼ íƒ€ì´í‹€ */
.accordion label {
    font-size: 20px !important;
    font-weight: 600 !important;
    color: #d63384 !important;
}

/* ë¡œê³  ì¤‘ì•™ ì •ë ¬ */
#logo-header {
    text-align: center;
    margin-top: 20px;
}
#logo-header img {
    width: 260px;
    height: auto;
    margin-bottom: 10px;
    filter: drop-shadow(0px 4px 6px rgba(0,0,0,0.1));
}
#logo-header p {
    color: #888;
    font-size: 18px;
    margin-top: 5px;
}

/* ì „ì²´ ì—¬ë°± ì¡°ì • */
#filter-row { margin-top: 5px !important; }
.accordion { margin-top: -10px !important; }

.tab-nav, .tab, .form {
    border-radius: 20px !important;
}

/* ê²°ê³¼ í…Œì´ë¸” */
.dataframe {
    background-color: #fff;
    border: 1.5px solid #ffb6c1 !important;
    border-radius: 20px !important;
    box-shadow: 0 3px 8px rgba(255, 182, 193, 0.2);
}

#run-btn {
    width: 200px !important;
    height: 110px !important;
    font-size: 20px !important;
}
"""
demo.launch(debug=False, share=True)
